{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Using Dataset Classes in PyTorch</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Scientist.: Dr.Eddy Giusepe Chirinos Isidro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em problemas de `Machine Learning` e `Deep Learning`, muito esforço é dedicado à preparação dos dados. Os dados geralmente são confusos e precisam ser pré-processados ​​antes de serem usados ​​para treinar um modelo. Se os dados não forem preparados corretamente, o modelo não poderá generalizar bem. Algumas das etapas comuns necessárias para o pré-processamento de dados incluem:\n",
    "\n",
    "* <font color=\"red\">Normalização de dados (`Data normalization`):</font> Isto inclui a normalização dos dados entre um intervalo de valores em um Dataset.\n",
    "\n",
    "* <font color=\"red\">Aumento de dados (`Data augmentation`):</font> Isso inclui a geração de novas amostras a partir das existentes, adicionando ruído ou mudanças nas features para torná-los mais diversos.\n",
    "\n",
    "A preparação de dados é uma etapa crucial em qualquer pipeline de Machine Learning. O `PyTorch` traz muitos módulos, como `torchvision`, que fornece Datasets e classes de Dataset para facilitar a preparação dos dados.\n",
    "\n",
    "Neste script, aprenderemos a como trabalhar com conjuntos de dados e transformações no `PyTorch` para que você possa criar suas próprias `classes de conjunto de dados personalizadas` e manipular os conjuntos de dados da maneira que desejar. Em particular, aprenderemos:\n",
    "\n",
    "* Como criar uma classe de `dataset` simples e aplicar transformações a ela.\n",
    "\n",
    "* Como criar transformações chamáveis ​​e aplicá-las ao objeto `dataset`.\n",
    "\n",
    "* Como compor várias transformações em um objeto `dataset`.\n",
    "\n",
    "Observe que aqui você jogará com conjuntos de dados simples para compreensão geral dos conceitos, enquanto na próxima parte deste script você terá a chance de trabalhar com objetos de `dataset` para imagens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando uma classe de conjunto de dados simples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de começar, teremos que importar alguns pacotes antes de criar a classe `dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fcbb53fc470>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importaremos a classe abstrata `Dataset` de `torch.utils.data`. Portanto, substituímos os métodos abaixo na classe dataset:\n",
    "\n",
    "* `__len__` para que `len(dataset)` possa nos dizer o tamanho do dataset.\n",
    "\n",
    "* `__getitem__` para acessar as amostras de dados no dataset suportando a operação de indexação. <font color=\"yellow\">Por exemplo:</font> `dataset[i]` pode ser usado para recuperar a i-ésima amostra de dados.\n",
    "\n",
    "Da mesma forma, `torch.manual_seed()` força a função aleatória a produzir o mesmo número toda vez que é recompilada.\n",
    "\n",
    "Agora, vamos definir a classe dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataset(Dataset):\n",
    "    # defining values in the constructor\n",
    "    def __init__(self, data_length = 20, transform = None):\n",
    "        self.x = 3 * torch.eye(data_length, 2)\n",
    "        self.y = torch.eye(data_length, 4)\n",
    "        self.transform = transform\n",
    "        self.len = data_length\n",
    "     \n",
    "    # Getting the data samples\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.x[idx], self.y[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)     \n",
    "        return sample\n",
    "    \n",
    "    # Getting data size/length\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No objeto construtor, criamos os valores das features e targets, ou seja , $x$ e $y$, atribuindo seus valores aos tensores `self.x` e `self.y`. Cada tensor carrega $20$ amostras de dados enquanto o atributo `data_length` armazena o número de amostras de dados. Vamos discutir sobre as transformações mais adiante.\n",
    "\n",
    "O comportamento do objeto `SimpleDataset` é como qualquer iterável do `Python`, como uma lista ou uma tupla. Agora, vamos criar o objeto `SimpleDataset` e observar seu comprimento total e o valor no índice $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the SimpleDataset object:  20\n",
      "accessing value at index 1 of the simple_dataset object:  (tensor([0., 3.]), tensor([0., 1., 0., 0.]))\n"
     ]
    }
   ],
   "source": [
    "dataset = SimpleDataset()\n",
    "\n",
    "print(\"length of the SimpleDataset object: \", len(dataset))\n",
    "print(\"accessing value at index 1 of the simple_dataset object: \", dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como nosso conjunto de dados é iterável, vamos imprimir os quatro primeiros elementos usando um loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 0.]) tensor([1., 0., 0., 0.])\n",
      "tensor([0., 3.]) tensor([0., 1., 0., 0.])\n",
      "tensor([0., 0.]) tensor([0., 0., 1., 0.])\n",
      "tensor([0., 0.]) tensor([0., 0., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    x, y = dataset[i]\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando transformações chamáveis (Creating Callable Transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em vários casos, você precisará criar transformações chamáveis ​​para `normalizar` ou `padronizar` os dados. Essas transformações podem então ser aplicadas aos `tensores`. Vamos criar uma transformação chamável e aplicá-la ao nosso objeto `\"dataset simples\"` que criamos anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a callable transform class mult_divide\n",
    "class MultDivide:\n",
    "    # Constructor\n",
    "    def __init__(self, mult_x = 2, divide_y = 3):\n",
    "        self.mult_x = mult_x\n",
    "        self.divide_y = divide_y\n",
    "\n",
    "    # caller\n",
    "    def __call__(self, sample):\n",
    "        x = sample[0]\n",
    "        y = sample[1]\n",
    "        x = x * self.mult_x\n",
    "        y =y / self.divide_y\n",
    "        sample = x, y\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criamos uma transformação customizada simples `MultDivide` que multiplica $x$ com $2$ e divide $y$ por $3$. Isso não é para uso prático, mas para demonstrar como uma classe chamável pode funcionar como uma transformação para nossa classe `dataset`. Lembre-se, declaramos um parâmetro `transform = None` no `simple_dataset`. Agora, podemos substituí-lo pelo objeto de transformação personalizado com `None` que acabamos de criar. \n",
    "\n",
    "\n",
    "Então, vamos demonstrar como isso é feito e chamar esse objeto de transformação em dataset para ver como ele transforma os quatro primeiros elementos de nosso dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idx:  0 Original_x:  tensor([3., 0.]) Original_y:  tensor([1., 0., 0., 0.])\n",
      "Idx:  0 Transformed_x: tensor([6., 0.]) Transformed_y: tensor([0.3333, 0.0000, 0.0000, 0.0000])\n",
      "Idx:  1 Original_x:  tensor([0., 3.]) Original_y:  tensor([0., 1., 0., 0.])\n",
      "Idx:  1 Transformed_x: tensor([0., 6.]) Transformed_y: tensor([0.0000, 0.3333, 0.0000, 0.0000])\n",
      "Idx:  2 Original_x:  tensor([0., 0.]) Original_y:  tensor([0., 0., 1., 0.])\n",
      "Idx:  2 Transformed_x: tensor([0., 0.]) Transformed_y: tensor([0.0000, 0.0000, 0.3333, 0.0000])\n",
      "Idx:  3 Original_x:  tensor([0., 0.]) Original_y:  tensor([0., 0., 0., 1.])\n",
      "Idx:  3 Transformed_x: tensor([0., 0.]) Transformed_y: tensor([0.0000, 0.0000, 0.0000, 0.3333])\n"
     ]
    }
   ],
   "source": [
    "# calling the transform object\n",
    "mul_div = MultDivide()\n",
    "custom_dataset = SimpleDataset(transform = mul_div)\n",
    " \n",
    "for i in range(4):\n",
    "    x, y = dataset[i]\n",
    "    print('Idx: ', i, 'Original_x: ', x, 'Original_y: ', y)\n",
    "    x_, y_ = custom_dataset[i]\n",
    "    print('Idx: ', i, 'Transformed_x:', x_, 'Transformed_y:', y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como você pode ver, a transformação foi aplicada com sucesso aos primeiros quatro elementos do conjunto de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compondo várias transformações para conjuntos de dados (Composing Multiple Transforms for Datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muitas vezes, gostaríamos de realizar várias transformações em série em um conjunto de dados. Isso pode ser feito importando a classe `Compose` do módulo de transformações no `torchvision`. Por exemplo, digamos que construímos outra transformação `SubtractOne` e a aplicamos ao nosso conjunto de dados, além da transformação `MultDivide` que criamos anteriormente.\n",
    "\n",
    "Depois de aplicada, a transformação recém-criada subtrairá $1$ de cada elemento do conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    " \n",
    "# Creating subtract_one tranform\n",
    "class SubtractOne:\n",
    "    # Constructor\n",
    "    def __init__(self, number = 1):\n",
    "        self.number = number\n",
    "        \n",
    "    # caller\n",
    "    def __call__(self, sample):\n",
    "        x = sample[0]\n",
    "        y = sample[1]\n",
    "        x = x - self.number\n",
    "        y = y - self.number\n",
    "        sample = x, y\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conforme especificado anteriormente, agora combinaremos ambas as transformações com o método `Compose`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Composing multiple transforms\n",
    "mult_transforms = transforms.Compose([MultDivide(), SubtractOne()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que a primeira transformação `MultDivide` será aplicada no conjunto de dados e, em seguida, a transformação `SubtractOne` será aplicada nos elementos transformados do conjunto de dados.\n",
    "Passaremos o objeto `Compose` (que contém a combinação de ambas as transformações: `MultDivide()` e `SubtractOne()`) para o nosso objeto `SimpleDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new simple_dataset object with multiple transforms\n",
    "new_dataset = SimpleDataset(transform = mult_transforms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que a combinação de múltiplas transformações foi aplicada ao conjunto de dados, vamos imprimir os primeiros quatro elementos do nosso conjunto de dados transformado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idx:  0 Original_x:  tensor([3., 0.]) Original_y:  tensor([1., 0., 0., 0.])\n",
      "Idx:  0 Transformed x_: tensor([ 5., -1.]) Transformed y_: tensor([-0.6667, -1.0000, -1.0000, -1.0000])\n",
      "Idx:  1 Original_x:  tensor([0., 3.]) Original_y:  tensor([0., 1., 0., 0.])\n",
      "Idx:  1 Transformed x_: tensor([-1.,  5.]) Transformed y_: tensor([-1.0000, -0.6667, -1.0000, -1.0000])\n",
      "Idx:  2 Original_x:  tensor([0., 0.]) Original_y:  tensor([0., 0., 1., 0.])\n",
      "Idx:  2 Transformed x_: tensor([-1., -1.]) Transformed y_: tensor([-1.0000, -1.0000, -0.6667, -1.0000])\n",
      "Idx:  3 Original_x:  tensor([0., 0.]) Original_y:  tensor([0., 0., 0., 1.])\n",
      "Idx:  3 Transformed x_: tensor([-1., -1.]) Transformed y_: tensor([-1.0000, -1.0000, -1.0000, -0.6667])\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    x, y = dataset[i]\n",
    "    print('Idx: ', i, 'Original_x: ', x, 'Original_y: ', y)\n",
    "    x_, y_ = new_dataset[i]\n",
    "    print('Idx: ', i, 'Transformed x_:', x_, 'Transformed y_:', y_)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juntando tudo, o código completo é o seguinte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the simple_dataset object:  20\n",
      "accessing value at index 1 of the simple_dataset object:  (tensor([0., 3.]), tensor([0., 1., 0., 0.]))\n",
      "Idx:  0 Original_x:  tensor([3., 0.]) Original_y:  tensor([1., 0., 0., 0.])\n",
      "Idx:  0 Transformed x_: tensor([ 5., -1.]) Transformed y_: tensor([-0.6667, -1.0000, -1.0000, -1.0000])\n",
      "Idx:  1 Original_x:  tensor([0., 3.]) Original_y:  tensor([0., 1., 0., 0.])\n",
      "Idx:  1 Transformed x_: tensor([-1.,  5.]) Transformed y_: tensor([-1.0000, -0.6667, -1.0000, -1.0000])\n",
      "Idx:  2 Original_x:  tensor([0., 0.]) Original_y:  tensor([0., 0., 1., 0.])\n",
      "Idx:  2 Transformed x_: tensor([-1., -1.]) Transformed y_: tensor([-1.0000, -1.0000, -0.6667, -1.0000])\n",
      "Idx:  3 Original_x:  tensor([0., 0.]) Original_y:  tensor([0., 0., 0., 1.])\n",
      "Idx:  3 Transformed x_: tensor([-1., -1.]) Transformed y_: tensor([-1.0000, -1.0000, -1.0000, -0.6667])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    " \n",
    "torch.manual_seed(2)\n",
    " \n",
    "class SimpleDataset(Dataset):\n",
    "    # defining values in the constructor\n",
    "    def __init__(self, data_length = 20, transform = None):\n",
    "        self.x = 3 * torch.eye(data_length, 2)\n",
    "        self.y = torch.eye(data_length, 4)\n",
    "        self.transform = transform\n",
    "        self.len = data_length\n",
    "     \n",
    "    # Getting the data samples\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.x[idx], self.y[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)     \n",
    "        return sample\n",
    "    \n",
    "    # Getting data size/length\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    " \n",
    "# Creating a callable tranform class mult_divide\n",
    "class MultDivide:\n",
    "    # Constructor\n",
    "    def __init__(self, mult_x = 2, divide_y = 3):\n",
    "        self.mult_x = mult_x\n",
    "        self.divide_y = divide_y\n",
    "    \n",
    "    # caller\n",
    "    def __call__(self, sample):\n",
    "        x = sample[0]\n",
    "        y = sample[1]\n",
    "        x = x * self.mult_x\n",
    "        y = y / self.divide_y\n",
    "        sample = x, y\n",
    "        return sample\n",
    " \n",
    "# Creating subtract_one tranform\n",
    "class SubtractOne:\n",
    "    # Constructor\n",
    "    def __init__(self, number = 1):\n",
    "        self.number = number\n",
    "        \n",
    "    # caller\n",
    "    def __call__(self, sample):\n",
    "        x = sample[0]\n",
    "        y = sample[1]\n",
    "        x = x - self.number\n",
    "        y = y - self.number\n",
    "        sample = x, y\n",
    "        return sample\n",
    " \n",
    "# Composing multiple transforms\n",
    "mult_transforms = transforms.Compose([MultDivide(), SubtractOne()])\n",
    " \n",
    "# Creating a new simple_dataset object with multiple transforms\n",
    "dataset = SimpleDataset()\n",
    "new_dataset = SimpleDataset(transform = mult_transforms)\n",
    " \n",
    "print(\"length of the simple_dataset object: \", len(dataset))\n",
    "print(\"accessing value at index 1 of the simple_dataset object: \", dataset[1])\n",
    " \n",
    "for i in range(4):\n",
    "    x, y = dataset[i]\n",
    "    print('Idx: ', i, 'Original_x: ', x, 'Original_y: ', y)\n",
    "    x_, y_ = new_dataset[i]\n",
    "    print('Idx: ', i, 'Transformed x_:', x_, 'Transformed y_:', y_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "188136318cf6055cba8ecc68b3950589dd9b0ac73e51fc52677697842d98696c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
